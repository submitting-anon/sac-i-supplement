{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts for Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to evaluate the trained agents\n",
    "\n",
    "- Use the flag `-t` to specify the model to be loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LunarLander with Bomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Evaluate baseline agent**\n",
    "\n",
    "`python3 eval_lunarT.py -t sac_lunarT_baseline_plus4_seed0 --noBomb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Expected evaluation results (100 episodes each seed)\n",
    ">\n",
    ">Seed: 0 \n",
    ">- Average Reward (n=99): 281.51(+-17.32), Min=244.33, Max=314.37\n",
    ">- Stats: n_success: 100, n_hits: 0\n",
    ">- Results saved in: ./eval_out/res_LunarLanderContinuous-v2_sac_lunarT_plus4_Nov18_seed0\n",
    ">- Computation time (minutes):  0.6\n",
    ">\n",
    ">Seed: 1\n",
    ">- Average Reward (n=99): 276.81(+-16.62), Min=232.63, Max=310.76\n",
    ">- Stats: n_success: 100, n_hits: 0\n",
    ">- Results saved in: ./eval_out/res_LunarLanderContinuous-v2_sac_lunarT_plus4_Nov18_seed1\n",
    ">- Computation time (minutes):  0.7\n",
    ">\n",
    ">Seed: 2\n",
    ">- Average Reward (n=99): 280.77(+-17.53), Min=240.49, Max=319.12\n",
    ">- Stats: n_success: 100, n_hits: 0\n",
    ">- Results saved in: ./eval_out/res_LunarLanderContinuous-v2_sac_lunarT_plus4_Nov18_seed2\n",
    ">- Computation time (minutes):  0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Evaluate baseline agent (bomb unaware lander)** \n",
    "\n",
    "`python3 eval_lunarT.py -t sac_lunarT_baseline_plus4_seed0`\n",
    "\n",
    ">Evaluation results (100 pisodes)\n",
    ">- Average Reward (n=99): 228.34(+-91.27), Min=22.75, Max=311.69\n",
    ">- Stats: n_success: 74, n_hits: 3, n_bombs=22\n",
    ">- Computation time (minutes):  4.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Evaluate the best SAC and SAC-I (circle reward shaping)**\n",
    "\n",
    "- SAC best agent:\n",
    "\n",
    "`python3 eval_lunarT.py --env LunarLanderContinuous-v2 -t sac_lunarTB_shapedC_seed4`\n",
    "\n",
    "- SAC-I best agent:\n",
    "\n",
    "`python3 eval_lunarT.py --env LunarLanderContinuous-v2 -t saci_lunarTB_shapedC_seed4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Expected evaluation results\n",
    ">\n",
    ">SAC agent:\n",
    ">- Average Reward (n=99): 258.09(+-70.80), Min=-95.76, Max=319.30\n",
    ">- Stats: n_success: 93, n_hits: 1, n_bombs=0\n",
    ">- Computation time (minutes):  7.7\n",
    ">\n",
    ">SAC-I agent:\n",
    ">- Average Reward (n=99): 252.97(+-77.70), Min=-83.75, Max=319.68\n",
    ">- Stats: n_success: 94, n_hits: 0, n_bombs=0\n",
    ">- Computation time (minutes):  7.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Evaluate the best SAC-I agent (conservative shaping)**\n",
    "\n",
    "`python3 eval_lunarT.py --env LunarLanderContinuous-v2 -t saci_lunarTB_shapedVVHA_seed5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Expected evaluation results\n",
    ">\n",
    ">- Average Reward (n=99): 268.44(+-39.45), Min=92.34, Max=314.33\n",
    ">- Stats: n_success: 97, n_hits: 0, n_bombs=3\n",
    ">- Computation time (minutes):  5.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BipedalWalkerHardcore-v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Evaluate the SAC agent trained in the BipedalWalker-v3 (easy version)**\n",
    "\n",
    "`python3 eval_bipedal.py -t sac_bipedal_baseline_seed0 --env BipedalWalker-v3`\n",
    "\n",
    ">This agent is good at running and will be used to train the other agents in the hardcore version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Evaluate SAC-I agents trained from scratch**\n",
    "\n",
    "Agent walks with legs-up: `python3 eval_bipedal.py -t saci_bipedalH_from0_seed0`\n",
    "\n",
    "Agent walks with legs-down: `python3 eval_bipedal.py -t saci_bipedalH_from0_seed1`\n",
    ">These agents are cool but the training is not so stable..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Evaluate the best SAC retrained from baseline agent**\n",
    "\n",
    "`python3 eval_bipedal.py -t sac_bipedalH_retrained_seed0`\n",
    "> Legs-up strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Evaluate the best SAC-I retrained from baseline agent**\n",
    "\n",
    "`python3 eval_bipedal.py -t saci_bipedalH_retrained_seed8`\n",
    "> Leg-up strategy. Evaluation average of 10 episodes +-278"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (EXTRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) Evaluate best SAC-I agents retrained from baseline agent (with extra bonus reward)**\n",
    "\n",
    "- Evaluate: `python3 eval_bipedal.py -t saci_bipedalH_retrained_bonus_seed1`\n",
    "> Seems to have an energy efficient walk (gets +=305 on Go trials) but falls more...\n",
    "- Evaluate: `python3 eval_bipedal.py -t saci_bipedalH_retrained_bonus_seed4`\n",
    "> Not so energy efficient (gets +=292 on Go trials) but falls less...\n",
    "- To evaluate on Go trials: just add the flag `--go`\n",
    "\n",
    "    `python3 eval_bipedal.py -t saci_bipedalH_retrained_bonus_seed1 --go`\n",
    "\n",
    "    `python3 eval_bipedal.py -t saci_bipedalH_retrained_bonus_seed4 --go` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Evaluate the SAC agents retrained from baseline agent (with extra bonus reward)**\n",
    "\n",
    "`python3 eval_bipedal.py -t sac_bipedalH_retrained_bonus_seed3`\n",
    "> Does not work... Interestingly, this agent starts to exploit getting stuck... :P schizophrenic agent... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
